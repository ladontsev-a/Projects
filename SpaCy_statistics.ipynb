{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5039b56",
   "metadata": {},
   "source": [
    "### Проверяем качество работы морфологического и синтаксического анализаторов SpaCy на корпусах из Universal Dependencies, размеченных в формате CoNLL-U\n",
    "Подробнее: https://universaldependencies.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d3cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c183a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "syntagrus = []\n",
    "f1 = open('ru_syntagrus-full.conllu', 'r', encoding='UTF-8')\n",
    "for tokenlist in conllu.parse_incr(f1):\n",
    "    syntagrus.append(tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5596a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "pud = []\n",
    "f2 = open('ru_pud-ud-test.conllu', 'r', encoding='UTF-8')\n",
    "for tokenlist in conllu.parse_incr(f2):\n",
    "    pud.append(tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51aad5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsd = []\n",
    "f3 = open('ru_gsd-full.conllu', 'r', encoding='UTF-8')\n",
    "for tokenlist in conllu.parse_incr(f3):\n",
    "    gsd.append(tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ee4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "taiga = []\n",
    "f4 = open('ru_taiga-full.conllu', 'r', encoding='UTF-8')\n",
    "for tokenlist in conllu.parse_incr(f4):\n",
    "    taiga.append(tokenlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d96f3",
   "metadata": {},
   "source": [
    "* предложние - объект класса conllu.models.TokenList; хранит токены\n",
    "* токен - объект класса conllu.models.Token; хранит грамматическую и синтаксическую информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09da69dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TokenList<«, Если, передача, цифровых, технологий, сегодня, в, США, происходит, впервые, ,, то, о, мирной, передаче, власти, такого, не, скажешь, », ,, –, написала, Кори, Шульман, ,, специальный, помощник, президента, Обамы, в, своем, блоге, в, понедельник, .>,\n",
       " conllu.models.TokenList,\n",
       " {'id': 3,\n",
       "  'form': 'передача',\n",
       "  'lemma': 'передача',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'feats': {'Animacy': 'Inan',\n",
       "   'Case': 'Nom',\n",
       "   'Gender': 'Fem',\n",
       "   'Number': 'Sing'},\n",
       "  'head': 9,\n",
       "  'deprel': 'nsubj',\n",
       "  'deps': None,\n",
       "  'misc': None},\n",
       " conllu.models.Token)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pud[0], type(pud[0]), pud[0][2], type(pud[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abe5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ru_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33b58710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_filter(corpus):\n",
    "    \n",
    "    '''takes a list of conllu labeled sentences\n",
    "    returns an output_list (list of lists), where output_list[x][0] is a spacy parsed sentence \n",
    "    and output_list[1] is an initial sentence from the corpus\n",
    "    and their tokens are identical'''\n",
    "    \n",
    "    output_list = []\n",
    "    \n",
    "    for sent in corpus:\n",
    "        actual_tokens = []\n",
    "        spacy_tokens = []\n",
    "        for w in sent:\n",
    "            actual_tokens.append(w['form'])\n",
    "            \n",
    "        for w in nlp(sent.metadata['text']):\n",
    "            spacy_tokens.append(w.text)\n",
    "        \n",
    "        if actual_tokens == spacy_tokens and len(spacy_tokens) == len(sent):\n",
    "            \n",
    "            output_list.append([nlp(sent.metadata['text']), sent])\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96c50d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_morph(corpus):\n",
    "    \n",
    "    '''takes output of tokens_filter function\n",
    "    returns accuracy metrics for lemmas, parts of speech and grammatical features '''\n",
    "    \n",
    "    sim_lemmas = 0\n",
    "    all_lemmas = 0\n",
    "    sim_pos = 0\n",
    "    all_pos = 0\n",
    "    sim_tags = 0\n",
    "    all_tags = 0\n",
    "    \n",
    "    for pair in corpus:\n",
    "        for i in range(len(pair[0])):\n",
    "            if pair[1][i]['upos'] != 'PUNCT':\n",
    "            \n",
    "                if pair[0][i].lemma_.lower() == pair[1][i]['lemma'].lower():\n",
    "                    sim_lemmas += 1\n",
    "                all_lemmas += 1\n",
    "            \n",
    "                if pair[0][i].pos_ == pair[1][i]['upos']:\n",
    "                    sim_pos += 1\n",
    "                all_pos += 1\n",
    "            \n",
    "                if pair[0][i].morph.to_dict() != {} and pair[1][i]['feats'] != None:\n",
    "                    \n",
    "                    # consider the same feature named differently in corpus sentence and in spacy parsed sentence   \n",
    "                    if 'StyleVariant' in pair[0][i].morph.to_dict() and 'Variant' in pair[1][i]['feats']:\n",
    "                        if pair[0][i].morph.to_dict()['StyleVariant'] == pair[1][i]['feats']['Variant']:\n",
    "                            sim_tags+=1\n",
    "                            \n",
    "                    # consider the same meaning named differently in corpus sentence and in spacy parsed sentence        \n",
    "                    if 'Person' in pair[0][i].morph.to_dict() and 'Person' in pair[1][i]['feats']:\n",
    "                    #    \n",
    "                        dict = pair[0][i].morph.to_dict()\n",
    "                        \n",
    "                        if dict['Person'] == 'First' and pair[1][i]['feats']['Person'] == '1':\n",
    "                            dict['Person'] = '1'\n",
    "                            \n",
    "                        elif dict['Person'] == 'Second' and pair[1][i]['feats']['Person'] == '2':\n",
    "                            dict['Person'] = '2'\n",
    "                        \n",
    "                        elif dict['Person'] == 'Third' and pair[1][i]['feats']['Person'] == '3':\n",
    "                            dict['Person'] = '3'\n",
    "                        \n",
    "                        if dict == pair[1][i]['feats']:\n",
    "                            sim_tags+=1           \n",
    "                        \n",
    "                    if pair[0][i].morph.to_dict() == pair[1][i]['feats']:\n",
    "                        sim_tags += 1\n",
    "                    all_tags += 1\n",
    "    \n",
    "    acc_lemmas = sim_lemmas / all_lemmas\n",
    "    acc_pos = sim_pos / all_pos\n",
    "    acc_tags = sim_tags / all_tags\n",
    "    \n",
    "    return acc_lemmas, acc_pos, acc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36e47e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_syntax(corpus):\n",
    "    \n",
    "    '''takes output of tokens_filter function\n",
    "    returns UAS and LAS metrics'''\n",
    "    \n",
    "    sim_heads = 0\n",
    "    sim_deprels = 0\n",
    "    heads = 0\n",
    "    \n",
    "    for pair in corpus:\n",
    "        for i in range(len(pair[0])):\n",
    "            if pair[1][i]['upos'] != 'PUNCT':\n",
    "                \n",
    "                if pair[1][i]['head'] == pair[0][i].head.i+1 \\\n",
    "                or (pair[1][i]['head'] == 0 and pair[1][i]['form'] == pair[0][i].head.text):\n",
    "                    sim_heads += 1\n",
    "                    \n",
    "                if pair[1][i]['deprel'] == pair[0][i].dep_ \\\n",
    "                or (pair[1][i]['deprel'] == 'root' and pair[0][i].dep_ == 'ROOT'):\n",
    "                    sim_deprels += 1\n",
    "                heads+=1\n",
    "                \n",
    "    UAS = sim_heads / heads\n",
    "    LAS = sim_deprels / heads\n",
    "    return UAS, LAS            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53fa8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "taiga_doc = tokens_filter(taiga)\n",
    "taiga_morph, taiga_syntax = compare_morph(taiga_doc), compare_syntax(taiga_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e65f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pud_doc = tokens_filter(pud)\n",
    "pud_morph, pud_syntax = compare_morph(pud_doc), compare_syntax(pud_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba83c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsd_doc = tokens_filter(gsd)\n",
    "gsd_morph, gsd_syntax = compare_morph(gsd_doc), compare_syntax(gsd_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "82c8ba83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "syntagrus_doc = tokens_filter(syntagrus)\n",
    "syntagrus_morph, syntagrus_syntax = compare_morph(syntagrus_doc), compare_syntax(syntagrus_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "26f080de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gsd</th>\n",
       "      <th>taiga</th>\n",
       "      <th>pud</th>\n",
       "      <th>syntagrus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_lemma</th>\n",
       "      <td>0.916095</td>\n",
       "      <td>0.898678</td>\n",
       "      <td>0.917125</td>\n",
       "      <td>0.906177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_pos</th>\n",
       "      <td>0.951431</td>\n",
       "      <td>0.924969</td>\n",
       "      <td>0.967212</td>\n",
       "      <td>0.964253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_features</th>\n",
       "      <td>0.853498</td>\n",
       "      <td>0.701178</td>\n",
       "      <td>0.905653</td>\n",
       "      <td>0.842082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   gsd     taiga       pud  syntagrus\n",
       "acc_lemma     0.916095  0.898678  0.917125   0.906177\n",
       "acc_pos       0.951431  0.924969  0.967212   0.964253\n",
       "acc_features  0.853498  0.701178  0.905653   0.842082"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_morph = pd.DataFrame()\n",
    "df_morph['gsd'] = gsd_morph\n",
    "df_morph['taiga'] = taiga_morph\n",
    "df_morph['pud'] = pud_morph\n",
    "df_morph['syntagrus'] = syntagrus_morph\n",
    "df_morph.rename({0: 'acc_lemma', 1: 'acc_pos', 2: 'acc_features'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6ce7c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gsd</th>\n",
       "      <th>taiga</th>\n",
       "      <th>pud</th>\n",
       "      <th>syntagrus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UAS</th>\n",
       "      <td>0.891469</td>\n",
       "      <td>0.837283</td>\n",
       "      <td>0.935365</td>\n",
       "      <td>0.903223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAS</th>\n",
       "      <td>0.860596</td>\n",
       "      <td>0.828951</td>\n",
       "      <td>0.912203</td>\n",
       "      <td>0.888220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gsd     taiga       pud  syntagrus\n",
       "UAS  0.891469  0.837283  0.935365   0.903223\n",
       "LAS  0.860596  0.828951  0.912203   0.888220"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syntax = pd.DataFrame()\n",
    "df_syntax['gsd'] = gsd_syntax\n",
    "df_syntax['taiga'] = taiga_syntax\n",
    "df_syntax['pud'] = pud_syntax\n",
    "df_syntax['syntagrus'] = syntagrus_syntax\n",
    "df_syntax.rename({0: 'UAS', 1: 'LAS'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
